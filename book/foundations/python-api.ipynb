{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DuckDB Python Integration\n",
    "\n",
    "## Introduction\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "## Sample Datasets\n",
    "\n",
    "## Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install duckdb pandas 'polars[pyarrow]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Library Import and Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DuckDB version: {duckdb.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Installing and Loading Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "con.install_extension(\"httpfs\")\n",
    "con.load_extension(\"httpfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT extension_name, loaded, installed FROM duckdb_extensions()\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common extensions for spatial data analysis\n",
    "extensions = [\"httpfs\", \"spatial\"]\n",
    "for ext in extensions:\n",
    "    con.install_extension(ext)\n",
    "    con.load_extension(ext)\n",
    "print(\"Extensions loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Reading Data from Multiple Sources\n",
    "\n",
    "### Verifying the Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT 42\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Reading CSV Files from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.read_csv(\"https://data.gishub.org/duckdb/cities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.read_csv(\"https://data.gishub.org/duckdb/countries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Understanding DuckDB Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = con.read_csv(\"https://data.gishub.org/duckdb/cities.csv\")\n",
    "large_cities = cities.filter(\"population > 1000000\").order(\"population DESC\").limit(10)\n",
    "large_cities.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Seamless Integration with Pandas DataFrames\n",
    "\n",
    "### Querying DataFrames with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.DataFrame({\"a\": [42]})\n",
    "con.sql(\"SELECT * FROM pandas_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cities data into a pandas DataFrame\n",
    "cities_df = con.read_csv(\"https://data.gishub.org/duckdb/cities.csv\").df()\n",
    "print(f\"Loaded {len(cities_df)} cities into pandas DataFrame\")\n",
    "cities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### The Bidirectional Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the pandas DataFrame using SQL\n",
    "large_cities = con.sql(\n",
    "    \"\"\"\n",
    "    SELECT name, country, population\n",
    "    FROM cities_df\n",
    "    WHERE population > 5000000\n",
    "    ORDER BY population DESC\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    ")\n",
    "large_cities.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Use SQL for initial filtering (DuckDB's strength)\n",
    "cities_rel = con.sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM read_csv_auto('https://data.gishub.org/duckdb/cities.csv')\n",
    "    WHERE population > 100000\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Step 2: Convert to DataFrame for pandas operations\n",
    "cities_df = cities_rel.df()\n",
    "\n",
    "# Step 3: Use pandas for complex transformations\n",
    "cities_df[\"pop_millions\"] = cities_df[\"population\"] / 1_000_000\n",
    "cities_df[\"hemisphere\"] = cities_df[\"latitude\"].apply(\n",
    "    lambda x: \"North\" if x > 0 else \"South\"\n",
    ")\n",
    "\n",
    "# Step 4: Query the transformed DataFrame with SQL\n",
    "result = con.sql(\n",
    "    \"\"\"\n",
    "    SELECT hemisphere, COUNT(*) as city_count,\n",
    "           AVG(pop_millions) as avg_pop_millions\n",
    "    FROM cities_df\n",
    "    GROUP BY hemisphere\n",
    "\"\"\"\n",
    ")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Performance Considerations\n",
    "\n",
    "## Polars Interoperability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install polars\n",
    "import polars as pl\n",
    "\n",
    "# Convert DuckDB result to Polars via pandas\n",
    "pl_df = pl.from_pandas(con.sql(\"SELECT * FROM range(10)\").df())\n",
    "pl_df.head()\n",
    "\n",
    "# Query Polars DataFrame in DuckDB\n",
    "con.sql(\"SELECT COUNT(*) AS n FROM pl_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Result Conversion and Output Formats\n",
    "\n",
    "### Converting to Python Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT 42\").fetchall()  # Returns [(42,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch a single row as a tuple\n",
    "con.sql(\"SELECT 42, 43\").fetchone()  # Returns (42, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch many rows (useful for batch processing)\n",
    "result = con.sql(\"SELECT * FROM range(100)\")\n",
    "result.fetchmany(10)  # Returns first 10 rows as list of tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Converting to Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT 42 AS answer\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Converting to NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = con.sql(\"SELECT range as id, range * 2 as doubled FROM range(5)\").fetchnumpy()\n",
    "print(f\"Keys: {result.keys()}\")\n",
    "print(f\"ID array: {result['id']}\")\n",
    "print(f\"Doubled array: {result['doubled']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Converting to Apache Arrow Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = con.sql(\"SELECT range as id FROM range(5)\").arrow()\n",
    "print(tbl.read_next_batch())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Choosing the Right Format\n",
    "\n",
    "## Writing Data To Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT 42\").write_parquet(\"out.parquet\")  # Write to a Parquet file\n",
    "con.sql(\"SELECT 42\").write_csv(\"out.csv\")  # Write to a CSV file\n",
    "con.sql(\"COPY (SELECT 42) TO 'out.parquet'\")  # Copy to a parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Persistent Storage and Database Files\n",
    "\n",
    "### Creating a Persistent Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or open a connection to a file called 'spatial_analysis.db'\n",
    "con = duckdb.connect(\"spatial_analysis.db\")\n",
    "\n",
    "# Create a table and load data into it\n",
    "con.sql(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cities AS\n",
    "    FROM read_csv_auto('https://data.gishub.org/duckdb/cities.csv')\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Query the table to verify it was created\n",
    "con.table(\"cities\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Connecting to Existing Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a new Python session or later in your workflow\n",
    "con = duckdb.connect(\"spatial_analysis.db\")\n",
    "\n",
    "# All your tables are still there\n",
    "con.sql(\"SHOW TABLES\").show()\n",
    "\n",
    "# Query your persisted data\n",
    "con.sql(\"SELECT COUNT(*) FROM cities\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Connection Management and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do your work with the connection\n",
    "con.sql(\"CREATE TABLE test AS SELECT 42 AS value\")\n",
    "\n",
    "# Explicitly close when done\n",
    "con.close()\n",
    "\n",
    "# After closing, attempting to use the connection will raise an error\n",
    "# con.sql(\"SELECT * FROM test\")  # This would fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The with statement guarantees cleanup\n",
    "with duckdb.connect(\"spatial_analysis.db\") as con:\n",
    "    con.sql(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS countries AS\n",
    "        FROM read_csv_auto('https://data.gishub.org/duckdb/countries.csv')\n",
    "    \"\"\"\n",
    "    )\n",
    "    con.table(\"countries\").show()\n",
    "    # Connection closes automatically when the block ends\n",
    "# Even if an error occurred above, the connection is now closed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Use Cases for Persistent vs In-Memory Databases\n",
    "\n",
    "## Prepared Statements and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "query = \"SELECT ?::INT AS a, ?::INT AS b, ?::INT + ?::INT AS sum\"\n",
    "con.execute(query, [2, 3, 2, 3]).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pop = 1000000\n",
    "con.execute(\n",
    "    \"SELECT COUNT(*) FROM read_csv_auto('https://data.gishub.org/duckdb/cities.csv') WHERE population > ?\",\n",
    "    [min_pop],\n",
    ").fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Installation and Basic Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### Exercise 2: Loading Remote Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### Exercise 3: SQL to DataFrame Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### Exercise 4: Querying DataFrames with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### Exercise 5: Bidirectional Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "### Exercise 6: Result Format Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "### Exercise 7: Persistent Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "### Exercise 8: Joining SQL and Python Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### Exercise 9: Writing Results to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "### Exercise 10: Practical Integration Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
